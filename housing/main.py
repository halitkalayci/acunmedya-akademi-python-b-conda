# Indexing => Proje dosyalarÄ±nÄ±zÄ±n Agent tarafÄ±ndan okunmasÄ±.

# `` -> Back Tick

# Prompt Engineering

# TÃ¼rkiye Ev Fiyat Tahmini - Random Forest Modeli
# Bu proje TÃ¼rkiye'deki ev fiyatlarÄ±nÄ± tahmin etmek iÃ§in Random Forest algoritmasÄ±nÄ± kullanÄ±r

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV
from sklearn.ensemble import RandomForestRegressor
from sklearn.preprocessing import LabelEncoder, StandardScaler
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
import pickle
import warnings
warnings.filterwarnings('ignore')

# TÃ¼rkÃ§e karakter desteÄŸi iÃ§in matplotlib ayarlarÄ±
plt.rcParams['font.family'] = ['DejaVu Sans']

print("ğŸ  TÃ¼rkiye Ev Fiyat Tahmini - Random Forest Modeli")
print("=" * 60)

# 1. VERÄ° YÃœKLEMESÄ° VE KEÅF ANALÄ°ZÄ°
print("\nğŸ“Š 1. Veri YÃ¼kleniyor...")
df = pd.read_csv('turkiye_ev_fiyatlari.csv')

print(f"âœ… Veri seti baÅŸarÄ±yla yÃ¼klendi!")
print(f"ğŸ“‹ Veri ÅŸekli: {df.shape}")
print(f"ğŸ“ˆ Ã–zellik sayÄ±sÄ±: {df.shape[1] - 1}")
print(f"ğŸ¯ Hedef deÄŸiÅŸken: fiyat_tl")

print(f"\nğŸ“Š Veri Seti Genel Bilgileri:")
print(df.info())

print(f"\nğŸ” Eksik Veri KontrolÃ¼:")
missing_data = df.isnull().sum()
if missing_data.sum() == 0:
    print("âœ… Eksik veri bulunmamaktadÄ±r!")
else:
    print(missing_data[missing_data > 0])

print(f"\nğŸ“ˆ Hedef DeÄŸiÅŸken (Fiyat) Ä°statistikleri:")
print(df['fiyat_tl'].describe())

# 2. VERÄ° Ã–N Ä°ÅLEME
print(f"\nğŸ”§ 2. Veri Ã–n Ä°ÅŸleme...")

# Kategorik deÄŸiÅŸkenleri belirleme
categorical_columns = ['sehir', 'ilce', 'ev_tipi', 'isinma_turu']
numerical_columns = ['metrekare', 'oda_sayisi', 'salon_sayisi', 'banyo_sayisi', 
                    'bina_yasi', 'bina_kat_sayisi', 'bulundugu_kat']
boolean_columns = ['balkon', 'asansor', 'park_yeri', 'site_icinde', 'esyali']

print(f"ğŸ“Š Kategorik Ã¶zellikler: {len(categorical_columns)}")
print(f"ğŸ”¢ SayÄ±sal Ã¶zellikler: {len(numerical_columns)}")
print(f"âœ… Boolean Ã¶zellikler: {len(boolean_columns)}")

# Kategorik verileri encode etme
label_encoders = {}
df_processed = df.copy()

for col in categorical_columns:
    le = LabelEncoder()
    df_processed[col] = le.fit_transform(df_processed[col])
    label_encoders[col] = le
    print(f"âœ… {col} encode edildi ({len(le.classes_)} sÄ±nÄ±f)")

# Boolean verileri 0/1'e Ã§evirme
for col in boolean_columns:
    df_processed[col] = df_processed[col].astype(int)

# 3. Ã–ZELLÄ°K VE HEDEF AYIRMA
print(f"\nğŸ¯ 3. Ã–zellik ve Hedef DeÄŸiÅŸken AyrÄ±mÄ±...")

X = df_processed.drop('fiyat_tl', axis=1)
y = df_processed['fiyat_tl']

print(f"ğŸ“Š Ã–zellik matrisi ÅŸekli: {X.shape}")
print(f"ğŸ¯ Hedef deÄŸiÅŸken ÅŸekli: {y.shape}")

# 4. VERÄ° BÃ–LME
print(f"\nâœ‚ï¸ 4. Veri EÄŸitim/Test BÃ¶lÃ¼mÃ¼...")

X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42, stratify=df_processed['sehir']
)

print(f"ğŸ‹ï¸ EÄŸitim seti: {X_train.shape}")
print(f"ğŸ§ª Test seti: {X_test.shape}")

# 5. RANDOM FOREST MODELÄ° EÄÄ°TÄ°MÄ°
print(f"\nğŸŒ² 5. Random Forest Modeli EÄŸitiliyor...")

# Temel Random Forest modeli
rf_model = RandomForestRegressor(
    n_estimators=100,
    max_depth=20,
    min_samples_split=5,
    min_samples_leaf=2,
    random_state=42,
    n_jobs=-1
)

# Modeli eÄŸitme
print("â³ Model eÄŸitimi baÅŸlÄ±yor...")
rf_model.fit(X_train, y_train)
print("âœ… Model eÄŸitimi tamamlandÄ±!")

# 6. TAHMÄ°N VE DEÄERLENDÄ°RME
print(f"\nğŸ“Š 6. Model Performans DeÄŸerlendirmesi...")

# EÄŸitim ve test tahminleri
y_train_pred = rf_model.predict(X_train)
y_test_pred = rf_model.predict(X_test)

# Metrikler hesaplama
train_mae = mean_absolute_error(y_train, y_train_pred)
test_mae = mean_absolute_error(y_test, y_test_pred)

train_mse = mean_squared_error(y_train, y_train_pred)
test_mse = mean_squared_error(y_test, y_test_pred)

train_rmse = np.sqrt(train_mse)
test_rmse = np.sqrt(test_mse)

train_r2 = r2_score(y_train, y_train_pred)
test_r2 = r2_score(y_test, y_test_pred)

print(f"\nğŸ“ˆ MODEL PERFORMANS METRÄ°KLERÄ°:")
print("=" * 50)
print(f"ğŸ“Š EÄÄ°TÄ°M SETÄ°:")
print(f"   MAE (Ortalama Mutlak Hata): {train_mae:,.0f} TL")
print(f"   MSE (Ortalama Kare Hata): {train_mse:,.0f}")
print(f"   RMSE (KÃ¶k Ortalama Kare Hata): {train_rmse:,.0f} TL")
print(f"   RÂ² Skoru: {train_r2:.4f}")

print(f"\nğŸ§ª TEST SETÄ°:")
print(f"   MAE (Ortalama Mutlak Hata): {test_mae:,.0f} TL")
print(f"   MSE (Ortalama Kare Hata): {test_mse:,.0f}")
print(f"   RMSE (KÃ¶k Ortalama Kare Hata): {test_rmse:,.0f} TL")
print(f"   RÂ² Skoru: {test_r2:.4f}")

# AÅŸÄ±rÄ± Ã¶ÄŸrenme kontrolÃ¼
overfitting_check = train_r2 - test_r2
print(f"\nğŸ” AÅIRI Ã–ÄRENME KONTROLÃœ:")
print(f"   EÄŸitim RÂ² - Test RÂ²: {overfitting_check:.4f}")
if overfitting_check < 0.1:
    print("   âœ… Model iyi genelleme yapÄ±yor")
elif overfitting_check < 0.2:
    print("   âš ï¸ Hafif aÅŸÄ±rÄ± Ã¶ÄŸrenme var")
else:
    print("   âŒ AÅŸÄ±rÄ± Ã¶ÄŸrenme problemi var")

# 7. Ã–ZELLÄ°K Ã–NEMÄ° ANALÄ°ZÄ°
print(f"\nğŸ¯ 7. Ã–zellik Ã–nem Analizi...")

feature_importance = pd.DataFrame({
    'feature': X.columns,
    'importance': rf_model.feature_importances_
}).sort_values('importance', ascending=False)

print(f"\nğŸ“Š EN Ã–NEMLÄ° 10 Ã–ZELLÄ°K:")
print("-" * 40)
for i, row in feature_importance.head(10).iterrows():
    print(f"{row['feature']:20s}: {row['importance']:.4f}")

# 8. CROSS VALÄ°DATÄ°ON
print(f"\nğŸ”„ 8. Cross Validation Analizi...")

cv_scores = cross_val_score(rf_model, X_train, y_train, cv=5, scoring='r2')
print(f"ğŸ“Š 5-Fold CV RÂ² SkorlarÄ±: {cv_scores}")
print(f"ğŸ“ˆ Ortalama CV RÂ² Skoru: {cv_scores.mean():.4f} (Â±{cv_scores.std()*2:.4f})")

# 9. MODEL KAYDETME
print(f"\nğŸ’¾ 9. Model Kaydediliyor...")

# Model ve encoder'larÄ± kaydetme
model_data = {
    'model': rf_model,
    'label_encoders': label_encoders,
    'feature_names': X.columns.tolist(),
    'feature_importance': feature_importance,
    'metrics': {
        'train_r2': train_r2,
        'test_r2': test_r2,
        'train_mae': train_mae,
        'test_mae': test_mae,
        'train_rmse': train_rmse,
        'test_rmse': test_rmse
    }
}

with open('ev_fiyat_tahmin_modeli.pkl', 'wb') as f:
    pickle.dump(model_data, f)

print("âœ… Model 'ev_fiyat_tahmin_modeli.pkl' olarak kaydedildi!")

# 10. Ã–RNEKLEMDEÄERLENDÄ°RME
print(f"\nğŸ  10. Ã–rnek Tahmin DeÄŸerlendirmesi...")

# Test setinden rastgele 5 Ã¶rnek
sample_indices = np.random.choice(X_test.index, 5, replace=False)

print(f"\nğŸ“‹ RASTGELE 5 EVÄ°N TAHMÄ°N SONUÃ‡LARI:")
print("-" * 60)
for idx in sample_indices:
    actual = y_test.loc[idx]
    predicted = rf_model.predict(X_test.loc[[idx]])[0]
    error = abs(actual - predicted)
    error_pct = (error / actual) * 100
    
    # Orijinal veri bilgileri
    original_data = df.loc[idx]
    
    print(f"ğŸ¡ Ev {idx}:")
    print(f"   ğŸ“ {original_data['sehir']} - {original_data['ilce']}")
    print(f"   ğŸ  {original_data['ev_tipi']}, {original_data['metrekare']}mÂ²")
    print(f"   ğŸ’° GerÃ§ek Fiyat: {actual:,.0f} TL")
    print(f"   ğŸ¯ Tahmin Fiyat: {predicted:,.0f} TL")
    print(f"   ğŸ“Š Hata: {error:,.0f} TL (%{error_pct:.1f})")
    print()

print(f"\nğŸ‰ MODEL GELÄ°ÅTÄ°RME TAMAMLANDI!")
print("=" * 60)
print(f"ğŸ“Š Model Ã–zeti:")
print(f"   â€¢ Algoritma: Random Forest Regressor")
print(f"   â€¢ Test RÂ² Skoru: {test_r2:.4f}")
print(f"   â€¢ Test RMSE: {test_rmse:,.0f} TL")
print(f"   â€¢ Test MAE: {test_mae:,.0f} TL")
print(f"   â€¢ Model DosyasÄ±: ev_fiyat_tahmin_modeli.pkl")
print(f"âœ… Model baÅŸarÄ±yla geliÅŸtirildi ve kaydedildi!")